{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspe\\anaconda3\\lib\\site-packages\\torchtext\\datasets\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\caspe\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\caspe\\anaconda3\\lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\caspe\\anaconda3\\lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Weird deprecation issues in torchtext means this cell needs to be run twice\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.vocab import vocab\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length: 1112300\n",
      "Unique characters: 80\n"
     ]
    }
   ],
   "source": [
    "with open('./1268-0.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "start_index = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_index = text.find('END OF THE PROJECT GUTENBERG')\n",
    "text = text[start_index:end_index]\n",
    "char_set = set(text)\n",
    "\n",
    "print(f'Total length: {len(text)}')\n",
    "print(f'Unique characters: {len(char_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1112300,)\n",
      "THE MYSTERIOUS  ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text],dtype=np.int32)\n",
    "print(f'Text encoded shape: {text_encoded.shape}')\n",
    "print(f'{text[:15]} ==> {text_encoded[:15]}')\n",
    "print(f'{text_encoded[15:21]} ==> {\"\".join(char_array[text_encoded[15:21]])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caspe\\AppData\\Local\\Temp\\ipykernel_25960\\1129553734.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks).to(device))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded)-chunk_size+1)]\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self,text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(),text_chunk[1:].long()\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks).to(device))\n",
    "seq_dl = DataLoader(seq_dataset,batch_size=batch_size,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target: 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "Input: 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "Target: 'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERIO'\n"
     ]
    }
   ],
   "source": [
    "for i,(seq,target) in enumerate(seq_dataset):\n",
    "    print(f'Input: {repr(\"\".join(char_array[seq.cpu()]))}')\n",
    "    print(f'Target: {repr(\"\".join(char_array[target.cpu()]))}')\n",
    "    if i == 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab_size,emebed_dim,rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,emebed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(emebed_dim,rnn_hidden_size,batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size,vocab_size)\n",
    "\n",
    "    def forward(self,x,hidden,cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.fc(out).reshape(out.size(0),-1)\n",
    "        return out,hidden,cell\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = torch.zeros(1,batch_size,self.rnn_hidden_size).to(device)\n",
    "        cell = torch.zeros(1,batch_size,self.rnn_hidden_size).to(device)\n",
    "        return hidden,cell\n",
    "\n",
    "model = RNN(vocab_size,embed_dim,rnn_hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss 4.3723\n",
      "Epoch: 500 loss 1.3515\n",
      "Epoch: 1000 loss 1.2633\n",
      "Epoch: 1500 loss 1.2541\n",
      "Epoch: 2000 loss 1.2370\n",
      "Epoch: 2500 loss 1.1626\n",
      "Epoch: 3000 loss 1.1691\n",
      "Epoch: 3500 loss 1.1978\n",
      "Epoch: 4000 loss 1.1997\n",
      "Epoch: 4500 loss 1.1420\n",
      "Epoch: 5000 loss 1.1020\n",
      "Epoch: 5500 loss 1.1045\n",
      "Epoch: 6000 loss 1.1528\n",
      "Epoch: 6500 loss 1.1148\n",
      "Epoch: 7000 loss 1.1598\n",
      "Epoch: 7500 loss 1.0989\n",
      "Epoch: 8000 loss 1.1595\n",
      "Epoch: 8500 loss 1.1759\n",
      "Epoch: 9000 loss 1.1153\n",
      "Epoch: 9500 loss 1.1612\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-3)\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden,cell = model.init_hidden(batch_size)\n",
    "    seq_batch,target_batch = next(iter(seq_dl))\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        preds,hidden,cell = model(seq_batch[:,c],hidden,cell)\n",
    "        loss += loss_fn(preds,target_batch[:,c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch: {epoch} loss {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "def sample(model,starting_str,len_generated_text=500,scale_factor=1.0):\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str]).to(device)\n",
    "    encoded_input = torch.reshape(encoded_input,(1,-1))\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden,cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _,hidden,cell = model(encoded_input[:,c].view(1),hidden,cell)\n",
    "    \n",
    "    last_char = encoded_input[:,-1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits,hidden,cell = model(last_char.view(1),hidden,cell)\n",
    "        logits = torch.squeeze(logits,0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "    \n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island, Herbert, document stowed it on fire, whether the difficient of the island,\n",
      "exclaimed with extreme mass of the first steps in the cave.\n",
      "\n",
      "The waters of the island, only eighthe again again at the corral. Pencroft and Gideon Spilett was very extent to make the Chimneys, and some day pass if they were allowed by his island of March, and since he was not been in some day, and the colonists had already five quadrupeds were carefully exposed towards the same time to land was produced by the corral,\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "print(sample(model,starting_str='The island',scale_factor=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
